---
title: "DaniÃ«l's Data"
output: html_document
---

```{r, messages=FALSE}
library(tidyverse)
```

# Organize and clean data

```{r}
#Read excel files in folder
files <- list.files(path = "responses", pattern = "\\.csv$")

#read in all separate data files into a single list
#gives warning that can be ignored (last line not empty)
datalist <- lapply(
  paste0("responses/", files), 
  function(x) suppressWarnings(read.table(x, header = F))
)

#determine max length to fill dataframe
max_length <- max(unlist(lapply(datalist,length)))

#fill dataframe
df_filled <- lapply(datalist,function(x) {
  ans <- rep(NA,length=max_length);
  ans[1:length(x)]<- x;
  return(ans)
})

colnamelist <- c("ID", "length", "response", "effect_size_abs", "effect_size", "true_mean1", "true_mean2", "obs_mean_1", "obs_mean2", "obs_mean_dif", "df", "tvalue", "pvalue", "obs_power", "d")

#combine lists into a dataframe, make numeric and rename columns
dat <- do.call(rbind, df_filled) %>%
  as.data.frame() %>%
  mutate_all(as.numeric) %>%
  rename_at(1:15, ~ colnamelist) %>%
  # deal with extra values on end of each line
  gather(key, val, 16:ncol(.)) %>%
  filter(!is.na(val)) %>%
  select(-key) %>%
  group_by_at(vars(one_of(colnamelist))) %>%
  nest()
```



## Create variables

```{r}
#create variable for correct/incorrect
#create variable for sig/nonsig

all_data <- dat %>%
  mutate(
    significant = ifelse(pvalue <= 0.05, 1, 0),
    response = recode(response, "0" = 0, "1" = 1, "2" = -1),
    right_answer = case_when( 
      (effect_size == 0) ~ 0,
      (effect_size > 0) ~ 1,
      (effect_size < 0) ~ -1
    ),
    correct = ifelse(response == right_answer, 1, 0)
  )

#subset data, only trials with more than 5 responses
all_data_sub <- filter(all_data, length > 5)
```

```{r}
# calculate percents for each judgment as sig for each effect_size
# for use in plots below
sub_pcnt <- all_data_sub %>%
  group_by(right_answer, effect_size) %>%
  summarise(
    pcnt_z = mean(response == 0),
    pcnt_p = mean(response == 1),
    pcnt_n = mean(response == -1),
    sig_z = sum(response == 0 & pvalue < .05)/sum(response == 0),
    sig_p = sum(response == 1 & pvalue < .05)/sum(response == 1),
    sig_n = sum(response == -1 & pvalue < .05)/sum(response == -1)
  ) %>%
  gather(key, val, pcnt_z:sig_n) %>%
  separate(key, c("key", "response")) %>%
  spread(key, val) %>%
  mutate(
    response = recode(response, "z" = 0, "p" = 1, "n" = -1),
    pcnt = round(pcnt, 2),
    sig = round(ifelse(is.nan(sig), 0, sig), 3),
    correct = right_answer == response
  )
```

## Plots

### Observed mean difference by effect size and response

```{r obs-mean-diff, fig.width = 16, fig.height = 10}
  ggplot() +
    geom_rect(data = sub_pcnt,
              aes(fill = correct),
              xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf, 
              alpha = 0.3, show.legend = FALSE) +
    geom_vline(data = all_data_sub, aes(xintercept = effect_size), color = "red") +
    geom_histogram(data = all_data_sub, aes(x=obs_mean_dif), 
                   binwidth = 0.1, color = "black", fill = "white") + 
    geom_text(data = sub_pcnt, aes(label = pcnt), x = -1.5, y = 25) +
    facet_grid(response~effect_size, labeller = label_both) +
    theme_bw() +
    scale_fill_manual(values = c("white", "grey50"))

ggsave("obs_mean_diff.png", width = 16, height = 10)

```

### P-values by effect size and response

```{r fig-p, fig.width = 16, fig.height = 10}
ggplot() +
  geom_rect(data = sub_pcnt, aes(fill = correct),
              xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf, 
              alpha = 0.3, show.legend = FALSE) +
  geom_histogram(data = all_data_sub, aes(x=pvalue),
                 binwidth = 0.05, boundary = 0, 
                 color = "black", fill = "white", alpha = 0.5) + 
  geom_text(data = sub_pcnt, aes(label = paste("%sig =", sig*100)), x = .2, y = 50) +
  facet_grid(response ~ effect_size, labeller = label_both) +
  theme_bw() +
  scale_fill_manual(values = c("white", "grey50"))

ggsave("power.png", width = 16, height = 10)
```

## Actual and observed d and power by effect size and response

(I filtered out rows with <= 5 observations)

```{r}
all_data_sub %>%
  group_by(effect_size, response, correct) %>%
  summarize(
    n = n(),
    mean_d = mean(-d, na.rm = T), #note -d because d in dataset is calculated in opposite diferection!
    power = mean(pvalue <= 0.05), 
    mean_obs_d = mean(obs_mean_dif, na.rm = T), 
    obs_power = mean(obs_power, na.rm = T)
  ) %>%
  mutate_if(is.double, round, 3) %>%
  filter(n > 5) %>%
  knitr::kable()

```

## Actual and observed d and power by effect size

(ignoring response)

```{r}
all_data_sub %>%
  group_by(effect_size) %>%
  summarize(
    n = n(),
    correct_pcnt = mean(correct),
    mean_d = mean(-d, na.rm = T), #note -d because d in dataset is calculated in opposite diferection!
    power = mean(pvalue <= 0.05), 
    mean_obs_d = mean(obs_mean_dif, na.rm = T), 
    obs_power = mean(obs_power, na.rm = T)
  ) %>%
  mutate_if(is.double, round, 3) %>%
  knitr::kable()

```

# Calculate X% of data

(I'm not sure what's going on here)

```{r}

find_cover_region <- function(x, alpha=0.5) {
  n <- length(x)
  x <- sort(x)
  k <- as.integer(round((1-alpha) * n))
  i <- which.min(x[seq.int(n-k, n)] - x[seq_len(k+1L)])
  c(x[i], x[n-k+i-1L])
}
tapply(-all_data_sub$d, all_data_sub$response, find_cover_region)
tapply(all_data_sub$obs_mean_dif, all_data_sub$response, find_cover_region)
```

## Cumulative means

Calculate cumulative means at each observation for each trial.

```{r}
cummeans <- all_data_sub %>%
  mutate(trial = row_number()) %>%
  unnest() %>%
  mutate(key = ifelse(val %in% c(1, 2), "grp", "val")) %>%
  group_by(trial, key) %>%
  mutate(obs_n = row_number()) %>%
  ungroup() %>%
  spread(key, val) %>%
  mutate(obs_n = ceiling(obs_n/2),
         grp = recode(grp, "1" = "A", "2" = "B")) %>%
  spread(grp, val) %>%
  mutate(val = B-A) %>%
  group_by(trial) %>%
  mutate(cummean = cumsum(val) / obs_n) %>%
  ungroup()
```

Plot cumulative means at each observation for effect size by response.

```{r plot_cumulative_means, fig.width=10, fig.height=10}
cummeans %>%
  ggplot(aes(obs_n, cummean, color = as.factor(trial))) +
  geom_hline(aes(yintercept = effect_size), color = "grey50") +
  geom_line(show.legend = FALSE) +
  facet_grid(effect_size~response, labeller = label_both)

ggsave("cummean.png", width = 10, height = 10)
```

```{r plot_cumulative_means_binned, fig.width=20, fig.height=15}

binwidth <- 10
cummeans %>%
  mutate(length_bin = ceiling(length/2/binwidth) * binwidth) %>%
  ggplot(aes(obs_n, cummean, group = as.factor(trial), color = as.factor(response))) +
  geom_hline(aes(yintercept = effect_size)) +
  geom_line(show.legend = FALSE) +
  facet_grid(effect_size~length_bin, labeller = label_both, scales = "free_x") +
  scale_color_manual(values = c(alpha("blue", .3), 
                                alpha("black", .3), 
                                alpha("red", .3))) +
  scale_x_continuous(breaks = seq(0, 150, by = binwidth)) +
  coord_cartesian(ylim = c(-2, 2)) +
  ggtitle("Cumulative means for decision length bins")

ggsave("cummean_binned.png", width = 20, height = 15)
```


```{r plot_cumulative_means_0, fig.width=20, fig.height=15}

binwidth <- 10
cummeans %>%
  filter(effect_size == 0) %>%
  mutate(length_bin = ceiling(length/2/binwidth) * binwidth) %>%
  ggplot(aes(obs_n, cummean, group = as.factor(trial), color = as.factor(response))) +
  geom_hline(aes(yintercept = effect_size)) +
  geom_line(show.legend = FALSE) +
  facet_grid(response~length_bin, labeller = label_both, scales = "free_x") +
  scale_color_manual(values = c(alpha("blue", .3), 
                                alpha("black", .3), 
                                alpha("red", .3))) +
  scale_x_continuous(breaks = seq(0, 150, by = binwidth)) +
  coord_cartesian(ylim = c(-2, 2)) +
  ggtitle("Cumulative means for decision length bins where effect size = 0")

ggsave("cummean_binned_0.png", width = 20, height = 15)
```


Some model comparison of predictors of correct responses. "after_N" variables are how close the cumulative mean is to the effect size after 10, 20, 30, etc observation pairs. This is probably not a great analysis strategy.

```{r}

maxlen <- 50

dat <- cummeans %>%
  filter(length/2 >= maxlen, obs_n %in% seq(10, maxlen, by = 10)) %>%
  mutate(obs_n = paste0("after_", obs_n),
         close = abs(cummean - effect_size)) %>%
  select(trial, effect_size, effect_size_abs, correct, obs_n, close) %>%
  spread(obs_n, close)


mod10 <- glm(correct ~ effect_size_abs + after_10, family = binomial, data = dat)
summary(mod10)

mod20 <- glm(correct ~ effect_size_abs + after_20, family = binomial, data = dat)
summary(mod20)

mod30 <- glm(correct ~ effect_size_abs + after_30, family = binomial, data = dat)
summary(mod30)

mod40 <- glm(correct ~ effect_size_abs + after_40, family = binomial, data = dat)
summary(mod40)

mod50 <- glm(correct ~ effect_size_abs + after_50, family = binomial, data = dat)
summary(mod50)

# compare models using AIC
library(AICcmodavg)
models <- list()
models[[1]] <- mod10
models[[2]] <- mod20
models[[3]] <- mod30
models[[4]] <- mod40
models[[5]] <- mod50
modelnames <- seq(10, maxlen, by = 10)
atab <- aictab(models, modelnames)
atab
```






